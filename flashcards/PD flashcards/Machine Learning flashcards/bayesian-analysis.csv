"power","probability of correctly rejecting null hypothesis when it's false"
"confidence level","probability of failing to reject null hypothesis when it is true"
"Bayes Theorem","p(A|B) = p(B|A) ⋅ p(A) / p(B)"
"prior","In Bayes Theorem, p(A). Probability expressing one's belief prior to taking evidence into account"
"posterior","In Bayes Theorem, p(A|B). Probability of unknown quantity, treated as random variable, conditional on evidence provided"
"likelihood","In Bayes Theorem, p(B|A). This is the observed data."
"marginal","In Bayest Theorem, p(B)"
"Intuition on posterior distribution","The weighted combination of the prior distribution and the likelihood distribution."
"stratified sampling","Randomly sampling from subpopulations independently. Avoids bias introduced by pure random sampling."
"region of practical equivalence (ROPE)","range around null hypothesis that indicates equivalence"
"highest density interval (HDI)","Area under probability curve equivalent to some percentage (e.g., 95%). Can fall within or outside defined ROPE."
"stratification","process of dividing members of population into homogenous subgroups before sampling"
"poststratification","method for adjusting sampling weights, usually to account for underrepresented groups in population"
"confidence interval","Frequentist approach. Interval constructed to estimate unknown fixed value."
"credible interval","Bayesian approach. Capture uncertainty about true parameter by imposing prior distribution."
"John Kruschke","Author of Doing Bayesian Data Analysis (the puppy dog book)"
"Andrew Gelman","Author of Bayesian Data Analysis (the red book)"
"homoskedasticity","Assumption of homogeneity of variance across all random variables."
"heteroskedasticity","Assumption of heterogeneity of variance across all random variables."
"Generalized Linear Model (GLM)","E(Y) = μ = g^-1(Xβ). Generalization of ordinary linear regression that allows linear model related to response variable by link function. Allow use an assumption set that better matches distribution."
"Two assumptions linear regressions make that GLMs don't","1. assume homogeneous variance; 2. assume normally-distributed error."
"Exponential family","Large class of probability distributions including normal, binomial, Poisson, gamma, etc"
"MCMC","Class of algorithms for sampling from probability distribution."
"residual","e = y-ŷ. Difference between observed value and predicted value, ŷ."
"Bernoulli distribution","Discrete probability distribution including response data that are binary (0 or 1)"
"Binomial distribution","Discrete probability distribution calculating the probability of exactly k successes in n independent trials that yield binary outcomes."
"Multinomial distribution","Discrete probability distribution calculating the probability of a specific set of fixed binary outcomes amongst k categories across n trials."
"Beta distribution","Family of continuous probability distributions on interval [0,1] with two shape parameters, α and β. Conjugate prior distribution of Bernoulli, binomial, negative binomial, and geometric distributions."
"conjugate prior","When prior and posterior are in the same probability distribution family. Algebraic convenience yielding closed-form expression for posterior distribution."
"If you don't have a conjugate prior...","Numerical integration may be required for calculating the posterior distribution."
"numerical integration","Broad family of algorithms for calculating numerical value of definite integral. E.g., integrand may only be known at certain points, as obtained by sampling."
"Maximum Likelihood Estimate (MLE)","After selecting a distribution, this technique can be used to fit distribution to observed data by maximizing probability of observed data. (E.g., if using normal distribution, technique evaluates options that result in best alignment for the mean, or the variance.)"
"Posterior Predictive Checks (PPCs)","1. Sample a λ from posterior distribution; 2. sample x from distribution using sampled λ (simulated datum); 3. repeat to generate histogram; 4. repeat to generate many histogram; 5. evaluate histograms using evaluation function; 6. look for statistical significance using p value"
"Goodness of Fit","Describes how well statistical model fits set of observed data, typically by summarizing discrepancy between observed values and expected values under model"
"latent variable","variables not directly observed but are inferred"
"latent function","functions representing a latent variable. (E.g., Gaussian process generates this.)"
"Thompson sampling","Sample parameters from posterior, and select arm with highest return (or select arms proportionate to the returns)"
"Bayesian Optimization (BayesOpt)","Sequential decision-making algorithm where each step selects new candidate to evaluate, and update posterior, shrinking uncertainty and exploring new points in space."
