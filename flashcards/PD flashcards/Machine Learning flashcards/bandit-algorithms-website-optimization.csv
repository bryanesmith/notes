"arm","in MAB terminology, this is an option (e.g., a particular experience)"
"epsilon-greedy algorithm","exploit with 1 - ε probability, explore with ε probability."
"active learning","algorithms that iteratively decide which labels they need"
"online learning","learning in real time (as opposed to batch learning)"
"Monte Carlo simulation","use of random repeat sampling for simulation"
"Bernoulli arm","arm that randomly draws a 1 or 0."
"horizon","number of pulls remaining for bandit"
"Softmax algorithm","selects arms randomly proportionate to average reward, with randomness introduced by temperature"
"annealing","slowly decreasing the temperature (or randomness)"
"temperature","variable that introduces randomness"
"explicitly curious algorithm","algorithms that intentionally explore options of higher uncertainty"
"Upper Confidence Bound (UCB) algorithm","deterministic bandit algorithm that selects arm based on upper-most part of confidence intervals for rewards"
"correlated bandits","when arms of a bandit can exploit correlations across arms (e.g., similar colors for logos)"
"contextual bandits","when bandits include background information (e.g., device type, visitor age) in its selection of action"
"blocked assignments","precompute bandit allocations and draw information for new traffic from a fast cache"
